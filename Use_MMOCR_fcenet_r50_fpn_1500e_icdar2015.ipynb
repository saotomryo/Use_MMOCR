{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saotomryo/Use_MMOCR/blob/main/Use_MMOCR_fcenet_r50_fpn_1500e_icdar2015.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IPmHECyfHPp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import json\n",
        "from skimage import measure\n",
        "import numpy as np\n",
        "print(torch.__version__)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"device = \", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xdkNklHDWku"
      },
      "source": [
        "## 環境準備 MMCV MMOCRのインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuhLiZC2ClOE"
      },
      "outputs": [],
      "source": [
        "#!pip install mmcv-full\n",
        "!pip install https://download.openmmlab.com/mmcv/dist/cu113/torch1.11.0/mmcv_full-1.4.7-cp37-cp37m-manylinux1_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install mmdetection\n",
        "!pip install mmdet"
      ],
      "metadata": {
        "id": "mEgPVLA6QwjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3WNFcX3PUcP"
      },
      "outputs": [],
      "source": [
        "HOME_PATH = \"/content\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKdRG66riHGN"
      },
      "outputs": [],
      "source": [
        "\n",
        "!git clone https://github.com/open-mmlab/mmocr.git\n",
        "%cd mmocr\n",
        "!pip install -r requirements/build.txt\n",
        "!pip install -v -e .  # or \"python setup.py develop\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDlSsCUcDlr_"
      },
      "source": [
        "## コンフィグファイルの編集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXx5P69_asuC"
      },
      "outputs": [],
      "source": [
        "%cd /content/mmocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQ_ZoxbmPLGn"
      },
      "outputs": [],
      "source": [
        "from mmcv import Config\n",
        "cfg = Config.fromfile('/content/mmocr/configs/textdet/fcenet/fcenet_r50_fpn_1500e_icdar2015.py')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## アノテーションフォルダの設定\n",
        "\n",
        "　以下の形式で作成したJSONファイルが必要です。\n",
        " 基本的には、 COCO Datasetと同様の形式になりますが、対象の文字列を記載したテキストファイルのファイル名を入れる必要があります。\n",
        "対象のテキストファイルは、ルートパスの下に\"annotation\"というフォルダを作成して、annotationフォルダから下のファイルパスを記載してください。\n",
        "\n",
        "- \n",
        "instances_test.json\n",
        "```   \n",
        "{  \n",
        "    \"images\":\n",
        "        [\"file_name\":画像ファイル名,  \n",
        "        \"height\":画像の高さ,  \n",
        "        \"width\":画像の横幅,  \n",
        "        \"segm_file\":文字列を保存したテキストファイルのファイル名,\n",
        "        \"id\",画像のファイルのID(一意）],   \n",
        "        [.....],  \n",
        "        ....,  \n",
        "    \"categories\":\n",
        "        [{\"id\": 1, \"name\": \"text\"}],  \n",
        "    \"annotations\":  \n",
        "        [{\"iscrowd\": 1(たくさんの文字があれば１),   \n",
        "        \"category_id\": \"1\"(基本的にはテキスト以外のものは対象がなので、常に1),   \n",
        "        \"bbox\": [左上のx座標, 左上のy座標, 高さ, 幅],   \n",
        "        \"area\": 面積（bboxから計算可能),  \n",
        "        \"segmentation\": [[x1, y1, x2, y2, x3 , y3 , x4 , y4 , .......]](ポリゴン形式で各頂点の座標を左周りに記入),   \n",
        "        \"image_id\": 画像のファイルID,   \n",
        "        \"id\": アノテーションのID(一意)}, \n",
        "        {....},  \n",
        "        ....\n",
        "    ]  \n",
        "}\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "BHf1vJQNVMeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## アノテーションフォルダの設定\n",
        "\n",
        "\n",
        "train_label_path = 訓練用のJSONファイル\n",
        "val_label_path = 検証用のJSONファイル\n",
        "\n",
        "# 画像ファイルのパス\n",
        "train_img_path = 訓練用画像ファイルのフォルダパス\n",
        "val_img_path = 検証用画像ファイルのフォルダパス\n",
        "\n",
        "# ルートフォルダ\n",
        "root_path = ルートフォルダのパス\n",
        "\n",
        "\n",
        "# 作業フォルダ（学習時のモデル出力先（エポック毎に出力))\n",
        "work_path = '/content/work_dir'"
      ],
      "metadata": {
        "id": "KZnP8V-FV4WN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pl4npPTBEiUK"
      },
      "outputs": [],
      "source": [
        "from mmdet.apis import set_random_seed\n",
        "\n",
        "# コンフィグを変更する\n",
        "# fcenet\n",
        "\n",
        "# 作業フォルダ\n",
        "cfg.work_dir = work_path\n",
        "\n",
        "# rootフォルダ\n",
        "cfg.data_root = root_path\n",
        "\n",
        "# アノテーションファイルのパス\n",
        "cfg.train.ann_file = train_label_path\n",
        "cfg.train.img_prefix = train_img_path\n",
        "cfg.test.ann_file = val_img_path\n",
        "cfg.test.img_prefix = val_img_path\n",
        "cfg.train_list[0].ann_file = train_label_path\n",
        "cfg.train_list[0].img_prefix = train_img_path\n",
        "cfg.test_list[0].ann_file = val_label_path\n",
        "cfg.test_list[0].img_prefix = val_img_path\n",
        "cfg.data.train.datasets[0].ann_file = train_label_path\n",
        "cfg.data.train.datasets[0].img_prefix = train_img_path\n",
        "cfg.data.test.datasets[0].ann_file = val_label_path\n",
        "cfg.data.test.datasets[0].img_prefix = val_img_path\n",
        "cfg.data.val.datasets[0].ann_file  = val_label_path\n",
        "cfg.data.val.datasets[0].img_prefix = val_img_path\n",
        "\n",
        "# The original learning rate (LR) is set for 8-GPU training.\n",
        "# We divide it by 8 since we only use one GPU.\n",
        "cfg.optimizer.lr = 0.001 / 8\n",
        "cfg.lr_config.warmup = None\n",
        "# Choose to log training results every 40 images to reduce the size of log file. \n",
        "cfg.log_config.interval = 40\n",
        "\n",
        "# Set seed thus the results are more reproducible\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "\n",
        "# Let's have a look at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n",
        "\n",
        "\n",
        "# 編集したコンフィグをファイル出力\n",
        "cfg.dump('/content/fcenet_r50_fpn_1500e_icdar2015.py')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mmocr.datasets import build_dataset\n",
        "from mmocr.models import build_detector\n",
        "from mmocr.apis import train_detector\n",
        "from mmocr.apis import init_detector\n",
        "import os.path as osp\n",
        "\n",
        "# Build dataset\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "\n",
        "# Build the detector\n",
        "model = build_detector(\n",
        "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
        "\n",
        "#追加学習をする場合\n",
        "#checkpoint = 学習済みモデルのファイルパス\n",
        "#model = init_detector(cfg, checkpoint, device=device)\n",
        "\n",
        "# Add an attribute for visualization convenience\n",
        "model.CLASSES = datasets[0].CLASSES\n",
        "\n",
        "# Create work_dir\n",
        "#mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "train_detector(model, datasets, cfg, distributed=False, validate=True)"
      ],
      "metadata": {
        "id": "6UvxMBq2GPwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWpWKp8xDps0"
      },
      "source": [
        "## 学習結果の確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4njK0yrgEcb7"
      },
      "outputs": [],
      "source": [
        "%cd /content/mmocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9LdgUnsSF0n"
      },
      "outputs": [],
      "source": [
        "\n",
        "from mmocr.apis import init_detector, model_inference\n",
        "\n",
        "img = #確認する画像ファイルのパス\n",
        "checkpoint = # 利用するモデルのパス\n",
        "out_file = # 出力するファイルのパス\n",
        "\n",
        "model = init_detector(cfg, checkpoint, device=device)\n",
        "if model.cfg.data.test['type'] == 'ConcatDataset':\n",
        "    model.cfg.data.test.pipeline = model.cfg.data.test['datasets'][0].pipeline\n",
        "\n",
        "result = model_inference(model, img)\n",
        "print(f'result: {result}')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "m--0IpZEDt4_"
      ],
      "machine_shape": "hm",
      "name": "Use_MMOCR_fcenet_r50_fpn_1500e_icdar2015.ipynb",
      "provenance": [],
      "mount_file_id": "1ayWgRrA3FpU65d1GgsinXvkDoWkjochJ",
      "authorship_tag": "ABX9TyOoCS9AWDzDjpiUSnxz8T82",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}